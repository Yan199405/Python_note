# scrapy框架使用

## 如何运行一个scrapy spider

以爬取scrapy提供的网页做实验：['http://quotes.toscrape.com/']
- 第一步：启动一个名为quotetutorial的框架
    - >scrapy startproject quotetutorial       
    
          (base) D:\Study\notepad\Python\崔庆元大神>scrapy startproject  quotetutorial
          New Scrapy project 'quotetutorial', using template directory 'd:\programdata\anaconda3\lib\site-packages\scrapy\templates\project', created in:
              D:\Study\notepad\Python\崔庆元大神\quotetutorial
         
          You can start your first spider with:
              cd quotetutorial
              scrapy genspider example example.com
             
- 第二步：根据启动框架的提示，创建spider

    - 先进入目录：
    
          (base) D:\Study\notepad\Python\崔庆元大神>cd quotetutorial
    - 执行创建：
    
          (base) D:\Study\notepad\Python\崔庆元大神\quotetutorial>scrapy genspider quotes quotes.toscrape.com
          Created spider 'quotes' using template 'basic' in module:
            quotetutorial.spiders.quotes
            
    - 这一步会生成quotes.py文件
    
- 第三步：启动scrapy
    - 启动命令
        
        >scrapy crawl quotes
        
## 目录结构和含义
如下所示：
    quotetutorial（主目录，由第一步生成）
    
    │  scrapy.cfg (指定了配置文件路径等基本信息)
    │
    └─quotetutorial（第一步生成的同名二级目录）
        │  items.py      保存数据结构
        │  middlewares.py     中间件
        │  pipelines.py       输出管道
        │  settings.py        配置信息，变量定义
        │  __init__.py
        │
        ├─spiders
        │  │  quotes.py       最主要的运行代码
        │__│  __init__.py     


## scrapy 调试
命令：
- scrapy shell www.xxx.com

## 保存输出内容
命令：
- scrapy crawl quotes -o quotes.json

   说明：支持输出的文件类型：supported list ('json', 'jsonlines', 'jl', 'csv', 'xml', 'marshal', 'pickle')
